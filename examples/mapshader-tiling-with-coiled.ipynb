{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c5181bc",
   "metadata": {},
   "source": [
    "### Setup a Conda Environment on Coiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6739e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import coiled\n",
    "\n",
    "coiled.create_software_environment(\n",
    "   name='mapshader-tiling',\n",
    "   conda={\n",
    "       'channels': ['conda-forge', 'defaults'],\n",
    "       'dependencies': [\n",
    "           'python=3.9',\n",
    "           'mapshader',\n",
    "           'dask=2022.04.2',\n",
    "           'distributed=2022.4.2',\n",
    "           'cloudpickle=2.0.0',\n",
    "           'spatialpandas',\n",
    "           'boto3',\n",
    "       ],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c7296",
   "metadata": {},
   "source": [
    "### Create Dask Cluster on Coiled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96ffb3b-165f-48cd-ba82-9bc02ae4f74e",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "31f8880b3f93490f8db2674ed60bdb06"
     ]
    },
    "id": "c96ffb3b-165f-48cd-ba82-9bc02ae4f74e",
    "outputId": "02d39e29-ee35-443c-fd41-137354731ad8"
   },
   "outputs": [],
   "source": [
    "from coiled.v2 import Cluster\n",
    "cluster = Cluster(name='mapshader-tiler',\n",
    "                  n_workers=10,\n",
    "                  worker_cpu=2,\n",
    "                  worker_options={\"nthreads\": 1},\n",
    "                  scheduler_memory=\"8 GiB\",\n",
    "                  software='mapshader-tiling')\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "print('Dashboard:', client.dashboard_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2597cf",
   "metadata": {},
   "source": [
    "### Clear cluster memory if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5ccd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0332ddc",
   "metadata": {},
   "source": [
    "## Tile World Cities (Sparse Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed76e59",
   "metadata": {},
   "source": [
    "### Setup Mapshader Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64daee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import mapshader\n",
    "import spatialpandas\n",
    "\n",
    "from mapshader.sources import VectorSource\n",
    "\n",
    "\n",
    "def world_cities_source():\n",
    "\n",
    "    # construct transforms\n",
    "    reproject_transform = dict(name='reproject_vector', args=dict(epsg=3857))\n",
    "    add_xy_fields_transform = dict(name='add_xy_fields', args=dict(geometry_field='geometry'))\n",
    "    buffered_extent_transform = dict(name='add_projected_buffered_extent', \n",
    "                                     args=dict(crs='4326',\n",
    "                                               buffer_distance=.01,\n",
    "                                               geometry_field='geometry'))\n",
    "    sp_transform = dict(name='to_spatialpandas', args=dict(geometry_field='geometry'))\n",
    "    \n",
    "    transforms = [reproject_transform,\n",
    "                  add_xy_fields_transform,\n",
    "                  buffered_extent_transform,\n",
    "                  sp_transform]\n",
    "\n",
    "    # construct value obj\n",
    "    source_obj = dict()\n",
    "    source_obj['name'] = 'World Cities'\n",
    "    source_obj['key'] = 'world-cities'\n",
    "    source_obj['text'] = 'World Cities'\n",
    "    source_obj['description'] = 'World Cities Point Locations'\n",
    "    source_obj['geometry_type'] = 'point'\n",
    "    source_obj['agg_func'] = 'max'\n",
    "    source_obj['cmap'] = ['aqua', 'aqua']\n",
    "    source_obj['shade_how'] = 'linear'\n",
    "    source_obj['dynspread'] = 2\n",
    "    source_obj['raster_interpolate'] = 'linear'\n",
    "    source_obj['xfield'] = 'X'\n",
    "    source_obj['yfield'] = 'Y'\n",
    "    source_obj['filepath'] = gpd.datasets.get_path('naturalearth_cities')\n",
    "    source_obj['transforms'] = transforms\n",
    "    source_obj['service_types'] = ['tile', 'wms', 'image', 'geojson']\n",
    "\n",
    "    return source_obj\n",
    "\n",
    "\n",
    "cities_source = VectorSource.from_obj(world_cities_source())\n",
    "cities_source.load()\n",
    "cities_source.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa0a560",
   "metadata": {},
   "source": [
    "### Example Mapshader to AWS S3 Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e3b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapshader.core import render_map\n",
    "from mapshader.sources import MapSource\n",
    "import os\n",
    "import sys\n",
    "from PIL.Image import fromarray\n",
    "import numpy as np\n",
    "\n",
    "from io import BytesIO\n",
    "\n",
    "def to_s3_tile(source: MapSource, output_location, z=0, x=0, y=0, tile_format='png'):\n",
    "\n",
    "    # we should create a render_tile function in mapshader core which has this logic...\n",
    "    if not source.is_loaded:\n",
    "        print(f'Dynamically Loading Data {source.name}', file=sys.stdout)\n",
    "        source.load()\n",
    "\n",
    "    img = render_map(source, x=int(x), y=int(y), z=int(z), height=256, width=256)\n",
    "    \n",
    "    if np.isnan(img.data).all():\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        import boto3\n",
    "    except ImportError:\n",
    "        raise ImportError('conda install boto3 to enable rendering to S3')\n",
    "\n",
    "    try:\n",
    "        from urlparse import urlparse\n",
    "    except ImportError:\n",
    "        from urllib.parse import urlparse\n",
    "        \n",
    "    # I don't think we need this but not sure...\n",
    "    img = fromarray(np.flip(img.data, 0), 'RGBA') \n",
    "\n",
    "    s3_info = urlparse(output_location)\n",
    "    bucket = s3_info.netloc\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    tile_file_name = '{}.{}'.format(y, tile_format.lower())\n",
    "    key = os.path.join(s3_info.path, str(z), str(x), tile_file_name).lstrip('/')\n",
    "    output_buf = BytesIO()\n",
    "    img.save(output_buf, tile_format)\n",
    "    output_buf.seek(0)\n",
    "    s3_client.put_object(Body=output_buf, Bucket=bucket, Key=key, ACL='public-read')\n",
    "    return 'https://{}.s3.amazonaws.com/{}'.format(bucket, key)\n",
    "\n",
    "\n",
    "to_s3_tile(cities_source, output_location='s3://mapshader-tiling-test-999/', x=1, y=1, z=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68291f5",
   "metadata": {},
   "source": [
    "### Create a Pandas DataFrame of Tile to Process based on Map Source feature extents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dec2b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapshader.tile_utils import get_tiles_by_extent\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "# TODO: Daskify this with delayed objects...if we have billions of tiles, workers should be able to \"generate\" tiles as they go...\n",
    "\n",
    "\n",
    "min_zoom = 0\n",
    "max_zoom = 18\n",
    "\n",
    "all_tiles = []\n",
    "for i, row in cities_source.data.iterrows():\n",
    "    for z in range(min_zoom, max_zoom+1):\n",
    "        tiles = get_tiles_by_extent(xmin=row['buffer_0_4326_xmin'],\n",
    "                                    ymin=row['buffer_0_4326_ymin'],\n",
    "                                    xmax=row['buffer_0_4326_xmax'],\n",
    "                                    ymax=row['buffer_0_4326_ymax'],\n",
    "                                    level=z)\n",
    "        for x, y, z, q in tiles:\n",
    "            tile = dict(x=x, y=y, z=z, q=q)\n",
    "            all_tiles.append(tile)\n",
    "            \n",
    "tiles_df = pd.DataFrame(all_tiles)\n",
    "tiles_df.drop_duplicates().sort_values(by=['z', 'x', 'y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e921f152",
   "metadata": {},
   "source": [
    "### Create Dask DataFrame and persist across cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb392711",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_ddf = dd.from_pandas(tiles_df, npartitions=200)\n",
    "tiles_ddf.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b16846d",
   "metadata": {},
   "source": [
    "### Map `tile to S3` helper function across tile partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac91fba4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tile_partition(df, output_location, source=None):\n",
    "    \n",
    "    def tile_row(row):\n",
    "        _ = to_s3_tile(source,\n",
    "                       output_location,\n",
    "                       x=row['x'],\n",
    "                       y=row['y'],\n",
    "                       z=row['z'])\n",
    "        return True\n",
    "    \n",
    "    \n",
    "    return df.apply(tile_row, axis=1)\n",
    "\n",
    "tiles_ddf.map_partitions(tile_partition,\n",
    "                         source=cities_source,\n",
    "                         output_location='s3://mapshader-tiling-test-999/').compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32088d09",
   "metadata": {},
   "source": [
    "### View tiles on OSM basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3160b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, TileLayer, basemaps, basemap_to_tiles\n",
    "\n",
    "tiles_url = 'https://mapshader-tiling-test-999.s3.amazonaws.com/{z}/{x}/{y}.png'\n",
    "tile_layer=TileLayer(url=tiles_url)\n",
    "\n",
    "from ipyleaflet import Map, basemaps, basemap_to_tiles\n",
    "\n",
    "m = Map(\n",
    "    basemap=basemap_to_tiles(basemaps.OpenStreetMap.Mapnik),\n",
    "    center=(48.204793, 350.121558),\n",
    "    zoom=3\n",
    "    )\n",
    "m\n",
    "\n",
    "m = Map(\n",
    "    basemap=basemap_to_tiles(basemaps.OpenStreetMap.Mapnik),\n",
    "    zoom=4,\n",
    "    scroll_wheel_zoom=True)\n",
    "\n",
    "m.add_layer(tile_layer)\n",
    "m\n",
    "display(m)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "CoiledDemo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
